{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#throwaway code to convert our list of csv's created manually into a list of events by country with source links\n",
    "import os,json\n",
    "def format_json_links():\n",
    "    files={}\n",
    "    for r,d,f in os.walk(r\"DataCSVs\"):\n",
    "        country = r[r.index('Vs')+3:]\n",
    "        if len(country)<1 or ('Canada' not in country) and ('United_States' not in country):\n",
    "            continue\n",
    "        files[country]={}\n",
    "        for file in f:\n",
    "            file = file[:file.index('.')]\n",
    "            files[country][file] = ''\n",
    "        \n",
    "    with open('events_sources.json','w')as json_file:\n",
    "        json.dump(files,fp=json_file,indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, pandas as pd, datetime, decimal\n",
    "def toDecimalConversion(number,quant=20):\n",
    "    quant = decimal.Decimal(str(quant))\n",
    "    quant = 1*10**(-quant)\n",
    "    decimal_return = decimal.Decimal(str(number)).quantize(quant)\n",
    "    return decimal_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'events_sources.json', 'r') as json_file:\n",
    "    sources_json=json.load(json_file)\n",
    "links=[]\n",
    "for k,v in sources_json.items():\n",
    "        for k2,v2 in v.items():\n",
    "            links.append((k,k2,v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException, ElementNotVisibleException, TimeoutException, ElementClickInterceptedException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time,bs4,re\n",
    "\n",
    "\n",
    "def check_end_of_consensus(source:str)->bool:\n",
    "    'check if last entry has consensus after clicking \"see more\"'\n",
    "    soup = bs4.BeautifulSoup(source,'html.parser')\n",
    "    source = soup.prettify()\n",
    "    info = re.findall('<tr.*?historicEvent.*?</tr>',source,re.DOTALL)\n",
    "    tries=0\n",
    "    for i in info[::-1]:#reverse order\n",
    "        consensus_re = re.search('.*?</td>.*?</td>.*?</td>.*?<td.*?\\n(.*?)\\n.*?</td>',i,re.DOTALL).group(1)\n",
    "        consensus_re = re.sub('[^0-9.]','',consensus_re)\n",
    "        try:\n",
    "            toDecimalConversion(consensus_re)\n",
    "            return False\n",
    "        except decimal.InvalidOperation :\n",
    "            tries+=1\n",
    "        if tries<16:\n",
    "            continue\n",
    "        else:\n",
    "            return True\n",
    "\n",
    "\n",
    "def extract_from_html(source:str,country,event_name):\n",
    "    extractDF = pd.DataFrame(columns=['Date','Time','Actual','Consensus'])\n",
    "    soup = bs4.BeautifulSoup(source,'html.parser')\n",
    "    source = soup.prettify()\n",
    "    info = re.findall('<tr.*?historicEvent.*?</tr>',source,re.DOTALL)\n",
    "    for i in info:\n",
    "        month_re = re.search('<td.*?\\n(.*?)\\n.*?</td>',i,re.DOTALL)\n",
    "        time_re = re.search('.*?</td>.*?<td.*?\\n(.*?)\\n.*?</td>',i,re.DOTALL)\n",
    "        actual_re = re.search('.*?</td>.*?</td>.*?<td.*?\\n.*?\\n(.*?)\\n.*?</td>',i,re.DOTALL).group(1)\n",
    "        consensus_re = re.search('.*?</td>.*?</td>.*?</td>.*?<td.*?\\n(.*?)\\n.*?</td>',i,re.DOTALL).group(1)\n",
    "        actual_re = re.sub('[^0-9.]','',actual_re)\n",
    "        consensus_re  = re.sub('[^0-9.]','',consensus_re)\n",
    "        \n",
    "        try:\n",
    "            actual_re = toDecimalConversion(actual_re,6)\n",
    "            consensus_re = toDecimalConversion(consensus_re,6)\n",
    "        except:\n",
    "            continue\n",
    "        time_re = time_re.group(1).strip()\n",
    "        row = {'Date':month_re.group(1),'Time':time_re,'Actual':actual_re,'Consensus':consensus_re}\n",
    "        extractDF.loc[len(extractDF)] = row\n",
    "        \n",
    "    extractDF['Difference'] = extractDF['Actual'] - extractDF['Consensus']\n",
    "    \n",
    "    extractDF['Actual'] = extractDF['Actual'].apply(pd.to_numeric)\n",
    "\n",
    "    extractDF['Consensus'] = pd.to_numeric(extractDF['Consensus'],errors='coerce')\n",
    "\n",
    "    \n",
    "\n",
    "    dst_str = {\n",
    "        2024:('2024-03-10','2024-11-03'),\n",
    "        2023:('2023-03-12','2023-11-05'),\n",
    "        2022:('2022-03-13','2022-11-06'),\n",
    "        2021:('2021-03-14','2021-11-07'),\n",
    "        2020:('2020-03-08','2020-11-01'),\n",
    "        2019:('2019-03-10','2019-11-03'),\n",
    "        2018:('2018-03-11','2018-11-04'),\n",
    "        2017:('2017-03-12','2017-11-05'),\n",
    "        2016:('2016-03-13','2016-11-06'),\n",
    "        2015:('2015-03-08','2015-11-01'),\n",
    "        2014:('2014-03-09','2014-11-02'),\n",
    "        2013:('2013-03-10','2013-11-03'),\n",
    "        2012:('2012-03-11','2012-11-04'),\n",
    "        2011:('2011-03-13','2011-11-06'),\n",
    "        2010:('2010-03-14','2010-11-07'),\n",
    "        2009:('2009-03-08','2009-11-01'),\n",
    "        2008:('2008-03-09','2008-11-02'),\n",
    "        }\n",
    "    dst = {}\n",
    "    for i in dst_str:\n",
    "        temptup = []\n",
    "        for j in dst_str[i]:\n",
    "            j = pd.to_datetime(j)\n",
    "            temptup.append(j)\n",
    "        dst[i] = temptup\n",
    "    extractDFDates = extractDF.copy()\n",
    "    for i,r in extractDF.iterrows():\n",
    "        if '(' in r[\"Date\"]:\n",
    "            date = re.search('(.*?)\\(.*',r['Date'])\n",
    "            newdate = date.group(1).strip()\n",
    "        else:\n",
    "            newdate = r['Date']\n",
    "        \n",
    "        newdate = f'{newdate} {r[\"Time\"]}'\n",
    "        newdate = pd.to_datetime(newdate)\n",
    "        if newdate>dst[newdate.year][0] and newdate<dst[newdate.year][1]:\n",
    "            newdate = newdate + datetime.timedelta(hours=8)\n",
    "        else:\n",
    "            newdate = newdate + datetime.timedelta(hours=7)\n",
    "        extractDFDates['Date'].at[i] = newdate\n",
    "    extractDFDates.drop(columns=['Time'],inplace=True) \n",
    "    try:\n",
    "        os.makedirs('Data')\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        os.makedirs(f'Data\\\\{country}')\n",
    "    except:\n",
    "        pass\n",
    "    extractDFDates.to_csv(f'Data\\\\{country}\\\\{event_name}.csv')\n",
    "\n",
    "\n",
    "def gather_data(links:list,event:int=0,clicks:int=0):\n",
    "    def x_button_find():\n",
    "        x_button = WebDriverWait(driver, 0.4).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, '//i[@class=\"popupCloseIcon largeBannerCloser\"]')))\n",
    "        if x_button:\n",
    "            x_button.click()\n",
    "        return 1\n",
    "    events_to_get = len(links)\n",
    "    link:str = links[event][2]\n",
    "    link_num = link[link.index('-',-4)+1:]\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.set_page_load_timeout(6)\n",
    "    try:\n",
    "        driver.get(link)\n",
    "    except TimeoutException:\n",
    "        print('bypass load')\n",
    "    try:\n",
    "        while True:\n",
    "            if clicks==0:\n",
    "                try:\n",
    "                    clicks = x_button_find()\n",
    "                except:\n",
    "                    pass\n",
    "            see_more_button = WebDriverWait(driver, 2).until(\n",
    "                    EC.element_to_be_clickable((By.XPATH, f'//div[@id=\"showMoreHistory{link_num}\"]')))\n",
    "            if see_more_button:\n",
    "                try:\n",
    "                    see_more_button.click()\n",
    "                except ElementClickInterceptedException:\n",
    "                    clicks = x_button_find()\n",
    "                    continue\n",
    "                if check_end_of_consensus(driver.page_source):\n",
    "                    html = driver.page_source\n",
    "                    driver.quit()\n",
    "                    extract_from_html(html,links[event][0],links[event][1])\n",
    "                    if event <events_to_get-1:\n",
    "                        gather_data(links,event+1)\n",
    "                        break\n",
    "                    else: break\n",
    "                        \n",
    "    except (NoSuchElementException, ElementNotVisibleException, TimeoutException) as e:\n",
    "        pass\n",
    "gather_data(links)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
