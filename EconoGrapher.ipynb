{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Overview\n",
    "\n",
    "This project was a personal project with myself and a friend, wherein we attempted to develop a system that could take a look at the history of economic events, for example the CPI month over month which indicates inflation, and get the price action at the exact time of the release of the event, track what happened in the market (the foreign exchange market or, currency exchange) and then graph those changes in a way that would allow us to develop a visual representation of the change in the market based on the differences between the expected value of the release, and the actual value of the release."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports, Initializing, and Settings\n",
    "\n",
    "We have mostly standard imports except for a few, `gather_data` is a file we created to access a website to scrape historical economic data, `glob` is a system module that allows for getting files within a folder, this is necessary to cycle through the events if you wanted to do so. `MetaTrader5` is the module for gathering the price action data, it allows access to almost all of the data stored on the MetaTrader account currently logged into on the computer running the script. Finally we have the `IPython-display` module which simple allows for manipulating some aspects of the this notebook within the code, you will see later it is used here to clear outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pandas as pd, glob, MetaTrader5 as mt5, matplotlib.pyplot as plt,typing\n",
    "from gather_data import gather_data\n",
    "from matplotlib.patches import Rectangle\n",
    "from datetime import timedelta\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# This code starts up the MetaTrader software\n",
    "mt5.initialize()\n",
    "\n",
    "# These lines set some visual options for pandas display within jupyter.\n",
    "pd.set_option('display.max_columns', 25)\n",
    "pd.set_option('display.max_colwidth', 25)\n",
    "pd.set_option('display.max_rows', 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Definitions\n",
    "\n",
    "`get_currency list` : this code simply returns the currency pairs that are relevant to a given sector denoted by a 3-letter code. For example, USD will contain all pairs that are directly effected by changes in the US economy, IDX will contain any market indexes, ect. This function is in place to allow quickly switching between what pairs you will want to be looking at for certain economic events. Eg. If you're looking at Australian inflation you won't want to look at USD based indexes and commodities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_currency_list(code:typing.Literal['USD', 'CAD', 'EUR', 'JPY', 'GBP', 'AUD', 'IDX', 'CMD']):\n",
    "    '''Return the list of currency pairs based on your desired common currency\n",
    "    \\n...\n",
    "    \\nIDX: Indices\n",
    "    \\nCMD: Commodities '''\n",
    "    switch_dict = {\n",
    "        'USD': ['EURUSD.p', 'GBPUSD.p', 'AUDUSD.p', 'USDCAD.p', 'USDJPY.p', 'USDCHF.p'],\n",
    "        'CAD': ['USDCAD.p', 'EURCAD.p', 'GBPCAD.p', 'AUDCAD.p', 'NZDCAD.p', 'CADCHF.p', 'CADJPY.p'],\n",
    "        'EUR': ['EURUSD.p', 'EURJPY.p', 'EURCAD.p', 'EURGBP.p', 'EURCHF.p', 'EURAUD.p', 'EURNZD.p'],\n",
    "        'JPY': ['USDJPY.p', 'EURJPY.p', 'GBPJPY.p', 'CADJPY.p', 'CHFJPY.p', 'AUDJPY.p', 'NZDJPY.p'],\n",
    "        'GBP': ['EURGBP.p', 'GBPUSD.p', 'GBPJPY.p', 'GBPCAD.p', 'GBPCHF.p', 'GBPAUD.p', 'GBPNZD.p'],\n",
    "        'AUD': ['EURAUD.p', 'GBPAUD.p', 'AUDUSD.p', 'AUDCAD.p', 'AUDJPY.p', 'AUDCHF.p', 'AUDNZD.p'],\n",
    "        'IDX': ['DJ30.s', 'SP500.s'],\n",
    "        'CMD': ['UKOUSD.p', 'XAUUSD.p', 'XAGUSD.p']\n",
    "    }\n",
    "    \n",
    "    return switch_dict.get(code, [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`timeFrameChoice` another simple function to allow quickly choosing between the time frame from which you want to extract data from MetaTrader, it allows for specifying a single numerical value in minutes or hours in place of typing the entire code in the MT5 syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeframe_choice(choice:typing.Literal[1,5,15,30,60,4,24]):\n",
    "    '''Allows you to determine your desired timeframe to access MetaTrader data.\n",
    "    \\nchoice = Literal[1min,5min,15min,30min,60min,4hr,24hr]\n",
    "    \\nReturns a mt5.TIMEFRAME_X choice\n",
    "    '''\n",
    "    timeframes = {1:mt5.TIMEFRAME_M1,5:mt5.TIMEFRAME_M5,15:mt5.TIMEFRAME_M15,\n",
    "                  30:mt5.TIMEFRAME_M30,60:mt5.TIMEFRAME_H1,4:mt5.TIMEFRAME_H4,24:mt5.TIMEFRAME_D1}\n",
    "    return timeframes[choice]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`get_price_data` this function executes a call to the MetaTrader software based on the given parameters, such as the time you want the data from and for how long, does some cleaning of unnecessary data from the table object returned by MT5 and then returns the cleaned table as a data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_price_data(symbol : str, timeframe : int, start : str, end : str)->pd.DataFrame:\n",
    "    '''Execute a call to MetaTrader for price data, and format for analysis \n",
    "    \\nsymbol: Choice of currency pair, selected from get_currency_list()\n",
    "    \\ntimeframe: Choice of timeframe, selected from timeframe_choice()\n",
    "\n",
    "    returns the cleaned table as a pd.Dataframe.\n",
    "    \n",
    "    '''\n",
    "    tf = timeframe_choice(timeframe)\n",
    "\n",
    "    start_date = pd.Timestamp(start)\n",
    "    end_date = pd.Timestamp(end)\n",
    "\n",
    "    rates = mt5.copy_rates_range(symbol, tf, start_date, end_date)   \n",
    "\n",
    "    df = pd.DataFrame(rates)\n",
    "\n",
    "    # If data is returned without error, convert time column object type to datetime, and drop unnecessary columns.\n",
    "    if not df.empty:\n",
    "        df['time'] = pd.to_datetime(df['time'], unit='s')\n",
    "        df.drop(columns=['tick_volume','real_volume', 'spread'],inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sell_chart & buy_chart` These two function perform nearly the same task however in the opposite manner, they are almost mirrors of one another except for the fact they deal with different column names. The purpose of these functions is to chart the returned price action data in a 2x2 grid of bar charts, to analyze the economic release from every angle. Each call to these functions represents one bar chart in the grid. For some of the releases a proper bar chart cannot be created since they have continuous values for the X variable of the chart (the difference in release value of the event compared to the projected value by economists) For example, inflation almost always comes out within 0.3% less than or above the expected value, which makes a bar chart with 7 values, however something like new jobs could range thousands or tens of thousands of unique values, so in the situations where this is the case there is code in place within this function to separate the releases into bins and then plot the bins rather than each unique value.\n",
    "\n",
    "There is also code within this function to plot certain relevant values as text on the chart which will be explained with green text within the code block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sell_chart(dataframe:pd.DataFrame, ax=None):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(8, 4.5))    \n",
    "    # If there is more than 11 unique values for X, then create bins based on groups, and get the mean for each value of each group.\n",
    "    if len(dataframe[\"Difference\"].unique()) > 11:\n",
    "        avg_neg_change = dataframe.groupby('Groups', observed=False)['max_negative_change'].mean()\n",
    "        high_before_low = dataframe.groupby('Groups', observed=False)['high_before_low'].mean()\n",
    "        average_mtl = dataframe.groupby('Groups', observed=False)['minutes_to_low'].mean()    \n",
    "        \n",
    "\n",
    "    # The same thing as the above code without the need for grouping by the groups.\n",
    "    else:\n",
    "        avg_neg_change = dataframe.groupby('Difference', observed=False)['max_negative_change'].mean()\n",
    "        high_before_low = dataframe.groupby('Difference', observed=False)['high_before_low'].mean()\n",
    "        average_mtl = dataframe.groupby('Difference', observed=False)['minutes_to_low'].mean() \n",
    "        \n",
    "\n",
    "    # Create a list containing the bin values as strings in order to supply to the graph's x label later, or in other words,\n",
    "    # this grabs the bin definition as text, for example if a bin is defined as (1, 3] which means all values between 1 and 2.99, this code will\n",
    "    # extract the text of \"(1,3]\"\n",
    "    avg_neg_list_keys = []\n",
    "    for k in avg_neg_change.index:\n",
    "        avg_neg_list_keys.append(str(k).replace(\"(\",\"\").replace(\"]\",\"\"))\n",
    "\n",
    "    # Creates a double bar chart centered on a y value of 0, technically a stacked bar chart, where the bars on the top represents\n",
    "    # the positive change in price (averaged) and the bars on the bottom represent negative change (averaged).\n",
    "    ax.bar(avg_neg_list_keys,high_before_low.values, color='green', zorder=2)\n",
    "    ax.bar(avg_neg_list_keys,(avg_neg_change.values)*-1, color='red', zorder=2)\n",
    "\n",
    "    # This code plots text on the chart based on important values to know\n",
    "    for i, value in enumerate(avg_neg_change.values):\n",
    "    # This code prints the risk/reward ratio on each bar, or in other words, the R/R given the economic release comes out at that value\n",
    "    # The if/else part of this code simply checks for a divide by 0 error and if one will arise it prints inf for \"infinite\" on the chart.\n",
    "        if value != 0 and high_before_low.values[i] != 0:\n",
    "            ax.text(i, -0.00025, round((value)/(high_before_low.values[i]), 3), \n",
    "                    ha='center', va='top', color='black',rotation = 315, zorder=3)\n",
    "        else:\n",
    "            ax.text(i, -0.00025, 'inf', ha='center', va='top', color='black',rotation = 315, zorder=3)\n",
    "    # This prints the average time it takes for the price action to peak after the release is dropped.\n",
    "        ax.text(i, 0.00025, f'{int(round(average_mtl.values[i], 0))}m', \n",
    "                ha='center', va='top', color='black', zorder=3)\n",
    "\n",
    "    # These two lines print the pearson correlation coefficients for when the difference (actual - expected) of the data release is above or below zero\n",
    "    ax.text(0.05, 0.05, round(dataframe[dataframe['Difference'] < 0]['Difference'].corr(dataframe[dataframe['Difference'] < 0]['max_negative_change']), 3), \n",
    "            transform=ax.transAxes, horizontalalignment='left', verticalalignment='bottom')\n",
    "    ax.text(0.95, 0.05, round(dataframe[dataframe['Difference'] > 0]['Difference'].corr(dataframe[dataframe['Difference'] > 0]['max_negative_change']), 3), \n",
    "            transform=ax.transAxes, horizontalalignment='right', verticalalignment='bottom')\n",
    "    # Plots the text for the bin titles extracted earlier on the chart\n",
    "    ax.set_xticks(avg_neg_list_keys)\n",
    "    ax.grid(True, axis='both', linestyle=\"--\", color='grey', zorder=1)\n",
    "    ax.set_facecolor('#e0e0e0')\n",
    "\n",
    "\n",
    "# All of the above explanations apply to the following code as well.\n",
    "def buy_chart(dataframe:pd.DataFrame, ax=None):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(8, 4.5))    \n",
    "    if len(dataframe[\"Difference\"].value_counts()) > 11:\n",
    "        avg_pos_change = dataframe.groupby('Groups', observed=False)['max_positive_change'].mean()\n",
    "        low_before_high = dataframe.groupby('Groups', observed=False)['low_before_high'].mean()\n",
    "        average_mth = dataframe.groupby('Groups', observed=False)['minutes_to_high'].mean()\n",
    "        # This gathers the count of how many times the economic event fall into each group\n",
    "        frequency = []\n",
    "        #using items() object to sort by the group bins from lowest to highest, and appending the frequencies in ascending order\n",
    "        for k,v in sorted(dataframe['Groups'].value_counts().items()):\n",
    "            frequency.append(v)\n",
    "\n",
    "    else:\n",
    "        avg_pos_change = dataframe.groupby('Difference', observed=False)['max_positive_change'].mean()\n",
    "        low_before_high = dataframe.groupby('Difference', observed=False)['low_before_high'].mean()\n",
    "        average_mth = dataframe.groupby('Difference', observed=False)['minutes_to_high'].mean()\n",
    "        frequency = []\n",
    "        for k,v in sorted(dataframe['Difference'].value_counts().items()):\n",
    "            frequency.append(v)\n",
    "\n",
    "    avg_neg_list_keys = []\n",
    "    for k in avg_pos_change.index:\n",
    "        avg_neg_list_keys.append(str(k).replace(\"(\",\"\").replace(\"]\",\"\"))\n",
    "\n",
    "    ax.bar(avg_neg_list_keys,(low_before_high.values)*-1, color='red', zorder=2)\n",
    "    ax.bar(avg_neg_list_keys,avg_pos_change.values, color='green', zorder=2)\n",
    "    for i, value in enumerate(avg_pos_change.values):\n",
    "        if value != 0 and low_before_high.values[i] != 0:\n",
    "            ax.text(i, 0.00025, round(value/(low_before_high.values[i]), 3), \n",
    "                    ha='center', va='bottom', color='black',rotation = 45, zorder=3)\n",
    "        else:\n",
    "            ax.text(i, 0.00025, 'inf', ha='center', va='bottom', color='black',rotation = 45, zorder=3)\n",
    "        ax.text(i, -0.00025, f'{int(round(average_mth.values[i], 0))}m', \n",
    "                ha='center', va='top', color='black', zorder=3)\n",
    "        \n",
    "    ax.text(0.05, 0.05, round(dataframe[dataframe['Difference'] < 0]['Difference'].corr(dataframe[dataframe['Difference'] < 0]['max_positive_change']), 3), transform=ax.transAxes,\n",
    "        horizontalalignment='left', verticalalignment='bottom')\n",
    "    ax.text(0.95, 0.05, round(dataframe[dataframe['Difference'] > 0]['Difference'].corr(dataframe[dataframe['Difference'] > 0]['max_positive_change']), 3), transform=ax.transAxes,\n",
    "        horizontalalignment='right', verticalalignment='bottom')\n",
    "    new_labels = [f\"{label} ({freq})\" for label, freq in zip(avg_neg_list_keys, frequency)]    \n",
    "    ax.set_xticks(avg_neg_list_keys)\n",
    "    ax.set_xticklabels(new_labels, rotation=315)\n",
    "    ax.grid(True, axis='both', linestyle=\"--\", color='grey', zorder=1)\n",
    "    ax.set_facecolor('#e0e0e0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Body\n",
    "\n",
    "This final section of code ties all of the above sections together, first it searches for the data file of the release, removes the outliers from the dataset, finds the list of pairs based on a given choice to `get_currency_list`, then gathers the data for the first currency pair in a returned list. From there it creates the necessary columns for the charts, then passes the data frame to a 2x2 subplot grid which contains 4 calls to the graph functions, 2 to `buy_chart` and 2 to `sell_chart`. The reason for calling each one twice is that as you will see, a graph for the short term effect (1 hour following release) of the release is given and also the long term effect (8 hours following release) The graph is then displayed and then entire code will run again in a cycle awaiting the user to hit the enter key which will cycle the graph to the next currency pair in the selected list."
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if input('Update database? y/n').lower() =='y':\n",
    "    gather_data()"
   ]
  },
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "currency_checkout = {'0':('Canada','CAD'),'1':('United_States','USD')}\n",
    "for k,v in currency_checkout.items():\n",
    "    print(f'{k}:\\n{v[0]}')\n",
    "print('Please input a number to select a currency to examine')\n",
    "choice = currency_checkout[input(f'Which currency to checkout?\\n{currency_checkout}')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = fr'Data\\{choice[0]}/*'\n",
    "# Gets all of the data files (CSVs) within the specified folder.\n",
    "csv_files = glob.glob(folder_path)\n",
    "for file in csv_files:\n",
    "    # Grabs the file name from the returned path of the current CSV.\n",
    "    file_name = os.path.basename(file)\n",
    "    if input(f'View graph for {file_name}? y/n').lower() == 'y':\n",
    "        data = pd.read_csv(file, index_col=0, parse_dates=['Date'])\n",
    "\n",
    "        # Grabs the list of currency pairs from the our pre-defined function, and iterates through them.\n",
    "        forex_symbols = get_currency_list(f'{choice[1]}')\n",
    "        for symbol in forex_symbols:\n",
    "            if input(f'View {symbol}? y/n').lower() == 'y':\n",
    "                pass\n",
    "            else:continue\n",
    "            data_1hr = data.copy()\n",
    "            for i, r in data.iterrows():\n",
    "                # Defines a variable that can add 60 minutes to the returned time of the economic release and then passes both times to the function\n",
    "                # that communicates with MetaTrader to get data for that hour with the granularity of 1 minute. I.e. a snapshot of the price action\n",
    "                # is taken every minute and added to a data frame which is returned to our function.\n",
    "                add_one_hour = timedelta(minutes=60)\n",
    "                short_term_rates = get_price_data(symbol, 1, r['Date'], r['Date'] + add_one_hour)\n",
    "\n",
    "                # Here we check if the data frame is valid, or that there is data within it, and if so, we define some variables we will\n",
    "                # need to create some new columns.\n",
    "                if not short_term_rates.empty:\n",
    "                    open = short_term_rates['open'].loc[0]\n",
    "                    data_1hr.loc[i, 'open'] = open\n",
    "\n",
    "                    # For every instance of an economic event (imagine we have a CSV of USD inflation events and there around 150 events) we\n",
    "                    # calculate the where the price peaked, when it peaked, and how much the difference is between the peak and the starting point\n",
    "                    max1h = short_term_rates['high'].max()\n",
    "                    idx_max = short_term_rates['high'].idxmax()\n",
    "                    max_pos_change_1hr = abs(max1h - open)\n",
    "\n",
    "                    min1h = short_term_rates['low'].min()\n",
    "                    idx_min = short_term_rates['low'].idxmin()\n",
    "                    max_neg_change_1hr = abs(min1h - open)\n",
    "                    \n",
    "                    # Here some new columns are created in the data set, that iteratively add the calculated fields of the data to an overall dataframe. \n",
    "                    data_1hr.loc[i, 'max_positive_change'] = max_pos_change_1hr\n",
    "                    data_1hr.loc[i, 'time_max'] = short_term_rates.loc[short_term_rates['high'] == max1h]['time'].values[0]\n",
    "                    data_1hr.loc[i, 'minutes_to_high'] = (data_1hr.loc[i, 'time_max'] - r['Date']).total_seconds() / 60\n",
    "                    # This value \"low_before_high\" is a little tricky to understand, it is the lowest price value before the peak, ONLY if\n",
    "                    # the peak occurred within the first minute of the release dropping. The reason for this is that some of these economic releases\n",
    "                    # can cause extremely volatile changes in the market, and it's possible that within the first minute that the price can peak\n",
    "                    # and then fall below where price opened at in that minute, and since we only have minute by minute snapshots of the data\n",
    "                    # it will appear as though the release is completely unprofitable when in fact if you have a system in place that can\n",
    "                    # automatically make trades then you can capture that initial burst of positive movement (or negative movement for a short trade)\n",
    "                    # so this code simply changes the low before high value in these cases from what could be a large negative one to a moot one.\n",
    "                    if data_1hr.loc[i, 'minutes_to_high'] == 0 and (max_neg_change_1hr >= 3*max_pos_change_1hr):\n",
    "                        data_1hr.loc[i, 'low_before_high'] = max_pos_change_1hr\n",
    "                    else:\n",
    "                        data_1hr.loc[i, 'low_before_high'] = abs(short_term_rates.loc[:idx_max + 1, 'low'].min() - open)\n",
    "\n",
    "                    # All of these values are mirrors of the ones above, calculating the opposite direction of the trade.\n",
    "                    data_1hr.loc[i, 'max_negative_change'] = max_neg_change_1hr\n",
    "                    data_1hr.loc[i, 'time_min'] = short_term_rates.loc[short_term_rates['low'] == min1h]['time'].values[0]\n",
    "                    data_1hr.loc[i, 'minutes_to_low'] = (data_1hr.loc[i, 'time_min'] - r['Date']).total_seconds() / 60\n",
    "                    if data_1hr.loc[i, 'minutes_to_low'] == 0 and (max_pos_change_1hr >= 3*max_neg_change_1hr):\n",
    "                        data_1hr.loc[i, 'high_before_low'] = max_neg_change_1hr\n",
    "                    else:\n",
    "                        data_1hr.loc[i, 'high_before_low'] = abs(short_term_rates.loc[:idx_min + 1, 'high'].max() - open)\n",
    "\n",
    "            # This code creates the groups that are needed to make the bar charts for releases with continuous release values.\n",
    "            # It does this by splitting the groups using quantiles, centered around 0, since 0 for an economic release generally represents a NULL\n",
    "            # or unpredictable effect on price action.\n",
    "            if len(data_1hr[\"Difference\"].value_counts()) > 11:\n",
    "                bins = [0,0.25,0.50,0.75,1]\n",
    "                quantiles = []\n",
    "                for i in bins:\n",
    "                    quantiles.append(data_1hr[data_1hr['Difference'] < 0]['Difference'].quantile(i))        \n",
    "                    quantiles.append(data_1hr[data_1hr['Difference'] > 0]['Difference'].quantile(i))\n",
    "                quantiles.sort()\n",
    "                data_1hr['Groups'] = pd.cut(data_1hr['Difference'], bins=quantiles, include_lowest=True, right=True,  duplicates='drop')\n",
    "    \n",
    "\n",
    "            # All of the above explanations apply to the following section, except the time period in the following code is 8 hours instead of 1.\n",
    "            data_8hr = data.copy()\n",
    "            for i, r in data.iterrows():\n",
    "                add_eight_hours = timedelta(minutes=480)        \n",
    "                long_term_rates = get_price_data(symbol, 5, r['Date'], r['Date'] + add_eight_hours)\n",
    "\n",
    "                if not long_term_rates.empty:\n",
    "                    open = long_term_rates['open'].loc[0]\n",
    "                    data_8hr.loc[i, 'open'] = open\n",
    "\n",
    "                    max8h = long_term_rates['high'].max()\n",
    "                    idx_max = long_term_rates['high'].idxmax()\n",
    "                    max_pos_change_8hr = abs(max8h - open)\n",
    "\n",
    "                    min8h = long_term_rates['low'].min()\n",
    "                    idx_min = long_term_rates['low'].idxmin() \n",
    "                    max_neg_change_8hr = abs(min8h - open)           \n",
    "\n",
    "                    data_8hr.loc[i, 'max_positive_change'] = max_pos_change_8hr\n",
    "                    data_8hr.loc[i, 'time_max'] = long_term_rates.loc[long_term_rates['high'] == max8h]['time'].values[0]\n",
    "                    data_8hr.loc[i, 'minutes_to_high'] = (data_8hr.loc[i, 'time_max'] - r['Date']).total_seconds() / 60\n",
    "                    if data_8hr.loc[i, 'minutes_to_high'] == 0 and (max_neg_change_8hr >= 3*max_pos_change_8hr):\n",
    "                        data_8hr.loc[i, 'low_before_high'] = max_pos_change_8hr\n",
    "                    else:\n",
    "                        data_8hr.loc[i, 'low_before_high'] = abs(long_term_rates.loc[:idx_max + 1, 'low'].min() - open)\n",
    "\n",
    "                    data_8hr.loc[i, 'max_negative_change'] = max_neg_change_8hr\n",
    "                    data_8hr.loc[i, 'time_min'] = long_term_rates.loc[long_term_rates['low'] == min8h]['time'].values[0]\n",
    "                    data_8hr.loc[i, 'minutes_to_low'] = (data_8hr.loc[i, 'time_min'] - r['Date']).total_seconds() / 60\n",
    "                    if data_8hr.loc[i, 'minutes_to_low'] == 0 and (max_pos_change_8hr >= 3*max_neg_change_8hr):\n",
    "                        data_8hr.loc[i, 'high_before_low'] = max_neg_change_8hr\n",
    "                    else:\n",
    "                        data_8hr.loc[i, 'high_before_low'] = abs(long_term_rates.loc[:idx_min + 1, 'high'].max() - open)     \n",
    "            \n",
    "            if len(data_8hr[\"Difference\"].value_counts()) > 11:\n",
    "                bins = [0,0.25,0.50,0.75,1]\n",
    "                quantiles = []\n",
    "                for i in bins:\n",
    "                    quantiles.append(data_8hr[data_8hr['Difference'] < 0]['Difference'].quantile(i))        \n",
    "                    quantiles.append(data_8hr[data_8hr['Difference'] > 0]['Difference'].quantile(i))\n",
    "                quantiles.sort()\n",
    "                data_8hr['Groups'] = pd.cut(data_8hr['Difference'], bins=quantiles, include_lowest=True, right=True,  duplicates='drop')\n",
    "            \n",
    "            \n",
    "            # The following code is responsible for the creation of the graph and all of its features, the line directly below initializes the graph.\n",
    "            fig, axs = plt.subplots(2, 2, figsize=(16, 12), sharex=True, sharey='row')\n",
    "            # Here are the previously mentioned calls to the chart functions that retrieve the chart objects and implant them in the subplot\n",
    "            # at the specified locations.\n",
    "            sell_chart(data_1hr, ax=axs[0, 0])\n",
    "            sell_chart(data_8hr, ax=axs[0, 1])\n",
    "            buy_chart(data_1hr, ax=axs[1, 0])\n",
    "            buy_chart(data_8hr, ax=axs[1, 1])\n",
    "            # Here are some titles, two for the columns, one for the x axis and one for the y axis.\n",
    "            axs[0, 0].set_title('Maximum 1hr change on ' + symbol + ' by ' + file_name, pad=10)\n",
    "            axs[0, 1].set_title('Maximum 8hr change on ' + symbol + ' by ' + file_name, pad=10)\n",
    "            fig.text(0.5, 0.02, 'Difference in data release actual to its expected value', ha='center', va='center', fontsize=14)\n",
    "            fig.text(0.02, 0.5, 'Max change in price (in pips)', ha='center', va='center', rotation='vertical', fontsize=14)\n",
    "            # The following code defines the center of the subplot object and colors in the background in red for the charts that show shorting\n",
    "            # potential and green for the charts that show buying potential.\n",
    "            center_y = axs[0, 0].get_position().y0\n",
    "            fig.patches.extend([\n",
    "                Rectangle((0, 0), 1, center_y, color='#99D775', alpha=1, transform=fig.transFigure, zorder=-1),\n",
    "                Rectangle((0, center_y), 1, 1 - center_y, color='#fc5656', alpha=1, transform=fig.transFigure, zorder=-1)])\n",
    "            plt.tight_layout(rect=[0.025, 0.025, 1, 1])\n",
    "            plt.show()\n",
    "            # This last section of code is what allows for the charts to be cycled from currency to currency instead of just printing all of the charts\n",
    "            # one after the other such as jupyter would normally do, this code prompts the user for an input, which if nothing is input and\n",
    "            # just enter is pressed, will cycle once, with the option to type \"done\" to quit cycling.\n",
    "            user_choice = input(\"Hit enter to continue or type \\'done\\' to quit\")\n",
    "            if user_choice != \"\" and user_choice.lower()!='done':\n",
    "                clear_output()\n",
    "                break\n",
    "            elif user_choice.lower()=='done':\n",
    "                break\n",
    "            clear_output()\n",
    "        if user_choice.lower() == \"done\":\n",
    "                break\n",
    "# Just prints a nice message but also serves as a confirmation that the code has executed to completion successfully.\n",
    "print(\"Program quit or no more pairs to analyze, have a good day!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
